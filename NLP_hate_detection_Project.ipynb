{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProjectXMG999/hate_speech_detection_Project/blob/main/NLP_hate_detection_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c5f3887-5ed7-4c42-bc33-57dcb51550fc",
      "metadata": {
        "id": "9c5f3887-5ed7-4c42-bc33-57dcb51550fc"
      },
      "source": [
        "## GPU set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2107fc-38dd-46a1-9043-65350cc82d41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd2107fc-38dd-46a1-9043-65350cc82d41",
        "outputId": "c7b7369b-77fa-47ce-f3b6-048c217203ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7f1b9be-f2e1-407c-89b5-0ab50789090d",
      "metadata": {
        "id": "c7f1b9be-f2e1-407c-89b5-0ab50789090d"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pbeyn5mG1K9J",
      "metadata": {
        "id": "pbeyn5mG1K9J"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272f722d-1680-4e16-add8-5085bf7a50f1",
      "metadata": {
        "id": "272f722d-1680-4e16-add8-5085bf7a50f1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "import random\n",
        "import operator\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import BertModel, BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ba6f892-fd29-4a1f-9a17-2efb6d2e2adf",
      "metadata": {
        "id": "4ba6f892-fd29-4a1f-9a17-2efb6d2e2adf"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Note that I will only use two of the columns: 'text' and 'HOF' (i.e. the label). The other columns (sentiment towards Trump, Biden and West) are superfluous to the current (simple) task. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315f77d2-4d1e-402d-8bd2-8047fa9dbebd",
      "metadata": {
        "id": "315f77d2-4d1e-402d-8bd2-8047fa9dbebd"
      },
      "outputs": [],
      "source": [
        "def load_data(path, sample_size=5, cols=['text', 'HOF'], label=None):\n",
        "    \"\"\"Helper function that loads data from a given path into a pandas\n",
        "       DataFrame, using only the specified cols. Also prints basic info\n",
        "       about the dataset size and displays a sample of the rows. \n",
        "    \"\"\"\n",
        "    \n",
        "    df = pd.read_csv(path, sep='\\t', usecols=cols)\n",
        "    \n",
        "    print(f\"\\nThere are {df.shape[0]} tweets in the {label} dataset.\")\n",
        "    print(\"\\nHere's a sample:\\n\")\n",
        "    display(df.sample(sample_size))\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FMvZ-Qzb1gBq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "FMvZ-Qzb1gBq",
        "outputId": "07379460-36ac-4ecc-8eaf-9f3fc74fa3bc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1dcc48af9cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-dc992a8710ae>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path, sample_size, cols, label)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nThere are {df.shape[0]} tweets in the {label} dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.tsv'"
          ]
        }
      ],
      "source": [
        "# Colab\n",
        "train = load_data('train.tsv', label='train')\n",
        "test = load_data('test.tsv', label='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5975a80f-1180-45c6-8559-6fe4571cb1b2",
      "metadata": {
        "id": "5975a80f-1180-45c6-8559-6fe4571cb1b2"
      },
      "outputs": [],
      "source": [
        "# Local\n",
        "# train = load_data(path=Path.cwd()/'data/GrimmingerKlingerWASSA2021/train.tsv', label='train')\n",
        "# test = load_data(path=Path.cwd()/'data/GrimmingerKlingerWASSA2021/test.tsv', label='test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82c728a5-f3f6-4358-a7f7-1e4a10e95f02",
      "metadata": {
        "id": "82c728a5-f3f6-4358-a7f7-1e4a10e95f02"
      },
      "outputs": [],
      "source": [
        "# Are there any duplicates?\n",
        "assert len(train['text'].drop_duplicates()) == len(train['text'])\n",
        "assert len(test['text'].drop_duplicates()) == len(test['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0015082-f682-4258-95f7-09317050a424",
      "metadata": {
        "id": "d0015082-f682-4258-95f7-09317050a424"
      },
      "source": [
        "## Quick inspection / visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GFaUGVtu1zY_",
      "metadata": {
        "id": "GFaUGVtu1zY_"
      },
      "outputs": [],
      "source": [
        "# !pip install matplotlib --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "873a9381-da14-47f0-8bda-729af7e96705",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "873a9381-da14-47f0-8bda-729af7e96705",
        "outputId": "afec320b-e8be-4ce6-fede-19294815554d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "# Distribution by class\n",
        "ax[0].bar(x = train['HOF'].unique(), # Data labels\n",
        "       height = train['HOF'].value_counts().values, # Num of tweets in each category\n",
        "       color='purple')\n",
        "\n",
        "ax[0].bar_label(ax[0].containers[0], label_type='edge', padding=3) # Annotate bars\n",
        "ax[0].set_ylim(0, 2300) # Raise upper limit of y-axis, to accommodate labels\n",
        "\n",
        "ax[0].set_title(\"Number of hateful/non-hateful tweets in the train dataset\", \n",
        "             fontweight='bold', fontsize=10, y = 1.02)\n",
        "ax[0].set_ylabel(\"Number of tweets\")\n",
        "ax[0].set_xlabel('Tweet label')\n",
        "\n",
        "# Distribution by length\n",
        "ax[1].hist([len(tweet) for tweet in train['text'].apply(lambda x: x.split())], \n",
        "           color='orange', rwidth=0.8)\n",
        "ax[1].set_xlabel('Token count')\n",
        "ax[1].set_ylabel('Number of tweets')\n",
        "ax[1].set_title(\"Histogram of tweet length\", \n",
        "                fontweight='bold', fontsize=10, y = 1.02)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ac50bc-50b4-4618-813e-251c736e1e53",
      "metadata": {
        "id": "00ac50bc-50b4-4618-813e-251c736e1e53"
      },
      "source": [
        "## Preprocess data\n",
        "At this stage, I will just map the labels to integers. Later, I will conduct more preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066df694-72b8-413e-88d1-c264b33f8488",
      "metadata": {
        "id": "066df694-72b8-413e-88d1-c264b33f8488"
      },
      "outputs": [],
      "source": [
        "# Map labels to binary integers\n",
        "label2id = {'Non-Hateful': 0, 'Hateful': 1}\n",
        "train['HOF'] = train['HOF'].apply(lambda x: label2id[x])\n",
        "test['HOF'] = test['HOF'].apply(lambda x: label2id[x])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9879452-c9a7-4920-9593-80d9c6c0c88c",
      "metadata": {
        "id": "d9879452-c9a7-4920-9593-80d9c6c0c88c"
      },
      "source": [
        "## Deal with class imbalances\n",
        "For simplicity / for now, I'll just downsample from the majority ('Non-Hateful') class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1087ed2d-0e52-47ef-b505-aa20a93e7128",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1087ed2d-0e52-47ef-b505-aa20a93e7128",
        "outputId": "d05b9fc2-2e1c-4aaa-831b-588df4b064bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before downsampling: \n",
            "Hateful: 293\n",
            "Non-Hateful: 2107\n",
            "\n",
            "After downsampling: \n",
            "Hateful: 293\n",
            "Non-Hateful: 293\n"
          ]
        }
      ],
      "source": [
        "print('Before downsampling: ')\n",
        "print(f\"Hateful: {len(train[train['HOF']==1])}\")\n",
        "print(f\"Non-Hateful: {len(train[train['HOF']==0])}\")\n",
        "\n",
        "train_hateful = train[train['HOF']==1]\n",
        "train_nonhateful = train[train['HOF']==0].sample(len(train_hateful))\n",
        "train_downsampled = pd.concat([train_hateful, train_nonhateful], axis=0).sample(frac=1)\n",
        "\n",
        "print('\\nAfter downsampling: ')\n",
        "print(f\"Hateful: {len(train_downsampled[train_downsampled['HOF']==1])}\")\n",
        "print(f\"Non-Hateful: {len(train_downsampled[train_downsampled['HOF']==0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c14cfc-644a-4ec0-a8cb-1125cd0ebd2d",
      "metadata": {
        "id": "45c14cfc-644a-4ec0-a8cb-1125cd0ebd2d"
      },
      "source": [
        "## Split train data set into train and development sets\n",
        "To provide a way to assess the model's performance after each training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d200564-3749-4a4a-a791-0f7bacaecf31",
      "metadata": {
        "id": "4d200564-3749-4a4a-a791-0f7bacaecf31"
      },
      "outputs": [],
      "source": [
        "# Split train data set into train and development sets\n",
        "train, dev = train_test_split(train_downsampled, test_size=0.5, stratify=train_downsampled['HOF'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dca382a5-9690-4b01-9d84-719637414aec",
      "metadata": {
        "id": "dca382a5-9690-4b01-9d84-719637414aec"
      },
      "source": [
        "## Prepare data\n",
        "\n",
        "\n",
        "* `torch.utils.data.Dataset` - stores the samples and their corresponding labels. I also use it to create a simple pipeline for cleaning and tokenizing the tweets. I will use the `bert-base-uncased` tokenizer so that the tokenizer matches the model. This is because (1) the model has a specific, fixed vocabulary, and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words. \n",
        "* `torch.utils.data.DataLoader` - wraps an iterable around the `Dataset`, enabling us to iterate through the samples. Can also be used to transform the data (if you provide a custom `collate_fn`). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4abbc280-c5ae-450d-9b38-b916b676d2f4",
      "metadata": {
        "id": "4abbc280-c5ae-450d-9b38-b916b676d2f4"
      },
      "outputs": [],
      "source": [
        "# Clean the tweets' text\n",
        "def clean_text(tweet):\n",
        "    \"\"\"A function that performs basic cleaning of a tweet's text.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Replace mentions and URLs with special token\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9_-]+\",'USR',tweet)\n",
        "    tweet = re.sub(r\"http\\S+\",'URL',tweet)\n",
        "    \n",
        "    # Remove \\n and \\t characters\n",
        "    tweet = tweet.replace('\\n', ' ')\n",
        "    tweet = tweet.replace('[NEWLINE]', ' ')\n",
        "    tweet = tweet.replace('\\t', ' ')\n",
        "    \n",
        "    # Strip whitespace\n",
        "    tweet = tweet.strip()\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    tweet = tweet.lower()\n",
        "    \n",
        "    # return [w.strip(punctuation) for w in tweet.split() if w.strip(punctuation)!='']\n",
        "    return tweet\n",
        "\n",
        "# train['cleaned_text'] = train['text'].apply(lambda x: clean_text(x))\n",
        "# test['cleaned_text'] = test['text'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0888abca-b22f-4c39-9818-dd5d21da546f",
      "metadata": {
        "id": "0888abca-b22f-4c39-9818-dd5d21da546f",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define Dataset class which cleans, tokenizes and encodes data\n",
        "class BERTDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        \n",
        "        # Initialize BERT tokenizer\n",
        "        # Note that I need to specify cache_dir because I'm using a venv\n",
        "        self.tok = BertTokenizer.from_pretrained('bert-base-uncased', cache_dir=Path.cwd()/'venv/lib/python3.8/site-packages')\n",
        "        \n",
        "        # Clean tweets\n",
        "        self.cleaned_tweets = data['text'].apply(lambda x: clean_text(x))\n",
        "        \n",
        "        # Truncate and encode tweets, up to max_length of 60\n",
        "        # While this is lower than BERT's max (512), it was chosen for computational speed\n",
        "        self.tweets = list(self.cleaned_tweets.apply(self.tok.encode, max_length=60, truncation=True))\n",
        "        \n",
        "        # Store labels\n",
        "        self.labels = list(data['HOF'])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        tweet = self.tweets[idx]\n",
        "        label = self.labels[idx]\n",
        "        return tweet, label\n",
        "    \n",
        "# Inspect an example\n",
        "# BD = BERTDataset(train.iloc[:5])\n",
        "# next(iter(BD))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57e6c0f5-b979-4caa-a028-efada141ee4f",
      "metadata": {
        "id": "57e6c0f5-b979-4caa-a028-efada141ee4f"
      },
      "outputs": [],
      "source": [
        "# Define collate function to be passed to DataLoader\n",
        "def bert_collate(batch):\n",
        "    \n",
        "    # Store batch size\n",
        "    batch_size = len(batch)\n",
        "    \n",
        "    # Separate tweets and labels\n",
        "    tweets = [t for t, _ in batch]\n",
        "    labels = torch.tensor([l for _, l in batch]).long()\n",
        "    \n",
        "    # Store length of longest tweet in batch\n",
        "    max_len = max(len(t) for t in tweets)\n",
        "    \n",
        "    # Create padded tweet and attention mask tensors\n",
        "    tweets_pad = torch.zeros((batch_size, max_len)).long()\n",
        "    masks_pad = torch.zeros((batch_size, max_len)).long()\n",
        "    for i, t in enumerate(tweets):\n",
        "        tweets_pad[i, :len(t)] = torch.tensor(t)\n",
        "        masks_pad[i, :len(t)] = 1\n",
        "        \n",
        "    return tweets_pad, masks_pad, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be599e0-0659-455e-96ed-c11605c9449b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3be599e0-0659-455e-96ed-c11605c9449b",
        "outputId": "a0a20fa1-e681-4d3c-aaab-432e00b71049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.21 s, sys: 16.8 ms, total: 1.23 s\n",
            "Wall time: 1.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Create data sets\n",
        "train_dataset = BERTDataset(train)\n",
        "dev_dataset = BERTDataset(dev)\n",
        "test_dataset = BERTDataset(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e06f9d8d-92f3-4ea3-b8ea-cf7f6a149c4c",
      "metadata": {
        "id": "e06f9d8d-92f3-4ea3-b8ea-cf7f6a149c4c"
      },
      "outputs": [],
      "source": [
        "# Create data loaders using torch.utils.data.DataLoader class\n",
        "# Using shuffle=True instead of specifying RandomSampler\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, collate_fn=bert_collate, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=100, collate_fn=bert_collate)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, collate_fn=bert_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0183c520-d528-4012-859d-4b66e103f0ed",
      "metadata": {
        "collapsed": true,
        "id": "0183c520-d528-4012-859d-4b66e103f0ed",
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Inspect\n",
        "for (idx, batch) in enumerate(train_loader):\n",
        "\n",
        "    print(f'\\n\\n--------------------- Batch {idx} ---------------------\\n')\n",
        "    \n",
        "    # Print the text\n",
        "    print(f\"There are {len(batch[0])} encoded tweets in this batch.\")\n",
        "    print('Tweets (encoded): ', batch[0])\n",
        "\n",
        "    # Print the label\n",
        "    print(f\"There are {len(batch[2])} encoded labels in this batch. Here they are: \")\n",
        "    print('Labels: ', batch[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a5d582-1871-4060-89e4-f9309672d486",
      "metadata": {
        "id": "31a5d582-1871-4060-89e4-f9309672d486"
      },
      "outputs": [],
      "source": [
        "# Define BERT classifier\n",
        "class BERTClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        # Specify network layers\n",
        "        # Note that I need to specify cache as I'm using a venv\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased', cache_dir=Path.cwd()/'venv/lib/python3.8/site-packages')\n",
        "        self.linear = nn.Linear(768, 4)\n",
        "        \n",
        "        # Define dropout\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "        # Freeze BERT layers\n",
        "        for n, p in self.bert.named_parameters():\n",
        "            p.requires_grad = False\n",
        "            \n",
        "    def forward(self, tweets, masks):\n",
        "        \n",
        "        # Define flow of tensors through the network\n",
        "        output_bert = self.bert(tweets, attention_mask=masks)[0].mean(axis=1)\n",
        "        return self.linear(self.dropout(output_bert))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06d91fe-61c5-41e4-b898-df69453cd32e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b06d91fe-61c5-41e4-b898-df69453cd32e",
        "outputId": "0310a43e-5795-41a3-b0d6-5110c0f7b800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Initialise model\n",
        "model = BERTClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407b8317-9e4c-4978-b7fb-c16c8fa840fa",
      "metadata": {
        "id": "407b8317-9e4c-4978-b7fb-c16c8fa840fa"
      },
      "source": [
        "The warning above: This only means that the pretrained head of the BERT model is discarded, and replaced with a randomly initialised classification head. It doesn't matter that this is randomly initialised because we will now fine-tune this new model head via training below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87742036-3111-4fe1-a096-4e0be8e2fd03",
      "metadata": {
        "id": "87742036-3111-4fe1-a096-4e0be8e2fd03"
      },
      "outputs": [],
      "source": [
        "# Move model to device\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1edb0b-dc7f-4bc4-ba17-9ef101dcd947",
      "metadata": {
        "id": "5c1edb0b-dc7f-4bc4-ba17-9ef101dcd947"
      },
      "outputs": [],
      "source": [
        "# Define optimiser, objective function and epochs\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16c17511-01e1-4356-bdbc-8ecfc61594a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16c17511-01e1-4356-bdbc-8ecfc61594a5",
        "outputId": "c8225d43-7091-49aa-ed3f-77dea8ab009a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after 1 epoch(s): 0.5767918088737202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  4.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after 2 epoch(s): 0.6109215017064846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after 3 epoch(s): 0.6416382252559727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  4.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after 4 epoch(s): 0.6757679180887372\n",
            "CPU times: user 8.3 s, sys: 17.4 ms, total: 8.32 s\n",
            "Wall time: 8.28 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Train model\n",
        "for epoch_i in range(1, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "        \n",
        "    # Put model into training mode. This is necessary so that the `Dropout`\n",
        "    # layers are activated. \n",
        "    model.train()\n",
        "    \n",
        "    # For each batch of the training data...\n",
        "    for i, batch in enumerate(tqdm(train_loader)):\n",
        "        \n",
        "        # Step 1. Since PyTorch accumulates gradients, clear any previously\n",
        "        # calculated gradients before performing a backward pass.\n",
        "        # PyTorch doesn't do this automatically because it can be useful while\n",
        "        # training RNNs.\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Step 2. Extract data and move to device.\n",
        "        tweets, masks, labels = [t.to(device) for t in batch]\n",
        "        \n",
        "        # Step 3. Forward pass - note that calling `model()` will in turn call\n",
        "        # the model's `forward()` function.\n",
        "        output = model(tweets, masks)\n",
        "        \n",
        "        # Step 4. Compute loss.\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        # Step 5. Perform backward pass to calculate gradients wrt each w and b term. \n",
        "        loss.backward()\n",
        "        \n",
        "        # Step 6. Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        # Step 7. Update parameters and take a step using the computed gradient.\n",
        "        optimizer.step()\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    \n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "    # Put model into evaluation mode, thereby deactivating Dropout layer.\n",
        "    model.eval()\n",
        "    \n",
        "    y_true = list()\n",
        "    y_pred = list()\n",
        "    \n",
        "    with torch.no_grad(): # We no longer need it to store computation graph.\n",
        "        for batch in dev_loader:\n",
        "            tweets, masks, labels = [t.to(device) for t in batch]\n",
        "            output = model(tweets, masks)\n",
        "            max_output = output.argmax(dim=1)\n",
        "            y_true.extend(labels.tolist())\n",
        "            y_pred.extend(max_output.tolist())\n",
        "            \n",
        "    print(f\"Accuracy after {epoch_i} epoch(s): {accuracy_score(y_true, y_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "402beb9a-c8d5-4f89-a06f-59850751da81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "402beb9a-c8d5-4f89-a06f-59850751da81",
        "outputId": "4c8a71f8-29f9-404d-8e4f-94a75de57573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.70\n",
            "\n",
            "Classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.71      0.81       541\n",
            "           1       0.18      0.59      0.28        59\n",
            "\n",
            "    accuracy                           0.70       600\n",
            "   macro avg       0.56      0.65      0.55       600\n",
            "weighted avg       0.87      0.70      0.76       600\n",
            "\n",
            "\n",
            "Confusion matrix: \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Predicted: Unhateful  Predicted: Hateful\n",
              "Actual: Unhateful                   385                 156\n",
              "Actual: Hateful                      24                  35"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1b610ab-d4a0-4b8b-8194-d3eac6c2a716\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted: Unhateful</th>\n",
              "      <th>Predicted: Hateful</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Actual: Unhateful</th>\n",
              "      <td>385</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual: Hateful</th>\n",
              "      <td>24</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1b610ab-d4a0-4b8b-8194-d3eac6c2a716')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1b610ab-d4a0-4b8b-8194-d3eac6c2a716 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1b610ab-d4a0-4b8b-8194-d3eac6c2a716');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.75 s, sys: 4.97 ms, total: 1.75 s\n",
            "Wall time: 2.21 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# ========================================\n",
        "#               Evaluation\n",
        "# ========================================\n",
        "\n",
        "# Evaluate model on test data\n",
        "model.eval()\n",
        "\n",
        "y_true = list()\n",
        "y_pred = list()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        tweets, masks, labels = [t.to(device) for t in batch]\n",
        "        output = model(tweets, masks)\n",
        "        max_output = output.argmax(dim=1)\n",
        "        y_true.extend(labels.tolist())\n",
        "        y_pred.extend(max_output.tolist())\n",
        "\n",
        "print('Test accuracy: {:.2f}'.format(accuracy_score(y_true, y_pred)))\n",
        "print('\\nClassification report: \\n', classification_report(y_true, y_pred))\n",
        "print('\\nConfusion matrix: \\n')\n",
        "display(pd.DataFrame({\"Predicted: Unhateful\": confusion_matrix(y_true, y_pred)[:, 0], \n",
        "              \"Predicted: Hateful\": confusion_matrix(y_true, y_pred)[:, 1]},\n",
        "             index=['Actual: Unhateful', 'Actual: Hateful']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b686f4a4-e904-4783-ae21-8cac3474204a",
      "metadata": {
        "id": "b686f4a4-e904-4783-ae21-8cac3474204a"
      },
      "source": [
        "## Comparison to baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f86d0ccc-b242-46b4-8a94-1847ad039b62",
      "metadata": {
        "id": "f86d0ccc-b242-46b4-8a94-1847ad039b62"
      },
      "source": [
        "### Basic baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5497a5f6-e58d-4570-9e01-1d8af287eb18",
      "metadata": {
        "id": "5497a5f6-e58d-4570-9e01-1d8af287eb18",
        "outputId": "a052469a-1d24-4ca7-8af3-83b4ad081f14",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95       541\n",
            "           1       0.00      0.00      0.00        59\n",
            "\n",
            "    accuracy                           0.90       600\n",
            "   macro avg       0.45      0.50      0.47       600\n",
            "weighted avg       0.81      0.90      0.86       600\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mattchapman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/mattchapman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Users/mattchapman/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Predict all majority class\n",
        "y_pred = [0] * len(test)\n",
        "y_true = test['HOF']\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3135979f-ed60-427a-b3a4-079959dd6693",
      "metadata": {
        "id": "3135979f-ed60-427a-b3a4-079959dd6693",
        "outputId": "0a8aa4e4-0728-495e-e358-31a995ddf788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       541\n",
            "           1       0.03      0.03      0.03        59\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.46      0.46      0.46       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Probabilistic guess\n",
        "maj_prob, min_prob = test['HOF'].value_counts(normalize=True).values\n",
        "y_pred = [0]*int(maj_prob*len(test)) + [1]*int(min_prob*len(test))\n",
        "y_pred = random.sample(y_pred, len(y_pred))\n",
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f651303-13b8-4e86-8d9f-3d3fe7076074",
      "metadata": {
        "id": "0f651303-13b8-4e86-8d9f-3d3fe7076074"
      },
      "source": [
        "### Naïve Bayes BoW classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b35defb-dc43-4519-bdb2-19e18076b985",
      "metadata": {
        "id": "4b35defb-dc43-4519-bdb2-19e18076b985"
      },
      "outputs": [],
      "source": [
        "from naive_bayes import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6240470a-1d5f-413e-a3f4-3da53ab51f5e",
      "metadata": {
        "id": "6240470a-1d5f-413e-a3f4-3da53ab51f5e",
        "outputId": "54786640-be51-4866-9f73-7f402ac2b18e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.69      0.78       541\n",
            "           1       0.11      0.34      0.16        59\n",
            "\n",
            "    accuracy                           0.65       600\n",
            "   macro avg       0.51      0.51      0.47       600\n",
            "weighted avg       0.83      0.65      0.72       600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate vocabs\n",
        "n_total, vocab, distinct_mentions = get_vocabs(train)\n",
        "\n",
        "# Generate MI list\n",
        "mi_list = sorted([(mi(w, distinct_mentions, n_total), w) for w in set(vocab[1]).union(set(vocab[0]))], reverse=True)\n",
        "\n",
        "# Estimate P(c_i), the probability of class c_i\n",
        "categories = [0, 1]\n",
        "prob_class = dict()\n",
        "total_tweets = len(train)\n",
        "for c_i in categories:\n",
        "    prob_class[c_i] = len(train[train['HOF']==c_i]) / total_tweets\n",
        "\n",
        "# Get predictions on test set using arbitrary values for n_features and smoothing_alpha\n",
        "# This is just to test that it works\n",
        "probs = naive_bayes_additive_smoothing_feature_selection(vocab, categories, 0.25, 1000, mi_list)\n",
        "labels, predictions = get_nb_predictions(categories, test, probs, prob_class)\n",
        "print(classification_report(labels, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8992b65d-6c54-4e79-bc16-b2503cfe38ab",
      "metadata": {
        "id": "8992b65d-6c54-4e79-bc16-b2503cfe38ab",
        "tags": []
      },
      "source": [
        "## Future improvements\n",
        "\n",
        "1. Better ways of dealing with class imbalances - e.g. upsampling, to avoid wasting data. \n",
        "\n",
        "2. Modify loss function to penalize False Positives and False Negatives with different magnitudes. E.g. if simple Cross Entropy looks like this:\n",
        "\n",
        "$$\\frac{-1}{N} \\sum_{i=1}^Ny_i \\cdot \\log(\\hat{y_i}) + (1 - y_i) \\cdot \\log(1 - \\hat{y_i})$$\n",
        "\n",
        "Where:\n",
        "* $y_i \\cdot \\log(\\hat{y_i})$ penalises False Negatives\n",
        "* $(1 - y_i) \\cdot \\log(1 - \\hat{y_i})$ penalises False Positives\n",
        "\n",
        "We could introduce some new scalar parameters to change the size/influence of these.\n",
        "\n",
        "3. Incorporate contextual information - original authors Grimminger and Klinger (2021) found that knowing whether or not a user was a supporter of a particular candidate massively boosted the F1 score. \n",
        "\n",
        "4. Interpretability - e.g. using LIME.\n",
        "\n",
        "5. Could try different levels of cleaning. BERT obviously needs contextual information, so I would only do limited cleaning, but could explore whether, for example, including some form of tagged users' names helps the model improve. \n",
        "\n",
        "6. Hyperparameter tuning\n",
        "\n",
        "7. I might consider making use of additional 🤗 Transformers tools like the `Trainer` object for more streamlined/customisable pipeline:\n",
        "\n",
        "```python \n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "933794ec-8fb1-4e95-97d1-d28994d5dad1",
      "metadata": {
        "id": "933794ec-8fb1-4e95-97d1-d28994d5dad1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}